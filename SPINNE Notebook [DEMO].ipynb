{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seated Posture assessment using Images and Neural NEtworks (SPINNE)\n",
    "\n",
    "<img src=\"Logo.png\" style=\"width: 500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desk posture classifier [DEMO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig1.png\">\n",
    "\n",
    "\n",
    "                    Figure 1: Desk dataset; A - good, B - bad back, C - bad neck, D - bad slouch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# libraries for webcam use\n",
    "import cv2\n",
    "from IPython import display\n",
    "\n",
    "# CUDA config\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "class_labels = {\n",
    "    0 : \"good\",\n",
    "    1 : \"bad - back\",\n",
    "    2 : \"bad - neck\",\n",
    "    3 : \"bad - slouch\"\n",
    "}\n",
    "\n",
    "def imshow(im,label):\n",
    "    plt.imshow(im.numpy().transpose((1,2,0))) # pytorch tensors for RGB images are 3xWxH\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    if(label != -1):\n",
    "        class_label = class_labels[int(label)]\n",
    "        if(class_label == 'good'):\n",
    "            print('\\033[92m' + class_label + '\\033[0m')\n",
    "        else:\n",
    "            print('\\033[91m' + class_label + '\\033[0m')\n",
    "            \n",
    "def classify_dataset(model,dataloader):\n",
    "    # this loop classifies the data and returns an overall accuracy when compared with the ground truth\n",
    "    n_images = len(dataloader.dataset)\n",
    "\n",
    "    # vector to store predictions for each image in test set\n",
    "    predictions = []\n",
    "\n",
    "    # keep track of predictions which match actual label (groudn truth)\n",
    "    n_matching_predictions = 0\n",
    "\n",
    "    # loop over all batches in the dataset\n",
    "    for images,labels in dataloader:\n",
    "        # get output from current network\n",
    "        if torch.cuda.is_available():\n",
    "            output = model(images.cuda())\n",
    "        else:\n",
    "            output = model(images)    \n",
    "\n",
    "        ps = torch.exp(output)\n",
    "\n",
    "        max_val,max_idx = ps.max(1)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            predictions.append(max_idx[i])\n",
    "            if(max_idx[i] == labels[i]):\n",
    "                n_matching_predictions += 1\n",
    "                \n",
    "    classification_accuracy = n_matching_predictions / n_images\n",
    "    \n",
    "    return predictions,classification_accuracy\n",
    "\n",
    "def get_labels(model,dataloader):\n",
    "    # this loop get the target labels and predicted labels - assumes a batch size of 1\n",
    "\n",
    "    # vector to store target labels for each image in test set\n",
    "    targets = []\n",
    "    # vector to store predictions for each image in test set\n",
    "    predictions = []\n",
    "\n",
    "    # loop over all batches in the dataset\n",
    "    for images,labels in dataloader:\n",
    "        # get output from current network\n",
    "        if torch.cuda.is_available():\n",
    "            output = model(images.cuda())\n",
    "        else:\n",
    "            output = model(images)    \n",
    "\n",
    "        ps = torch.exp(output)    \n",
    "\n",
    "        predictions.append(output.argmax(dim=1))\n",
    "        targets.append(labels)\n",
    "            \n",
    "    return targets, predictions\n",
    "\n",
    "# this is from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    classes = ['good','bad - back','bad - neck','bad - slouch']\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load classifier CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Define SpinNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2 (with dropout and two hidden layers with activations in fcn)\n",
    "\n",
    "class SpinNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # feature extraction (convolution and pooling)\n",
    "        self.conv_1 = nn.Conv2d(3,16,kernel_size=(3,3),padding=(1,1))\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=(3,3), stride=3)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(16,32,kernel_size=(3,3),padding=(1,1))\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(3,3), stride=3)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(32,16,kernel_size=(3,3),padding=(1,1))\n",
    "        self.pool_3 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        \n",
    "        # classifier (fully connected network)\n",
    "        self.hidden_1 = nn.Linear(1344,256)\n",
    "        self.hidden_2 = nn.Linear(256,256)\n",
    "        self.output_layer = nn.Linear(256,4)\n",
    "        self.classification_fn = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.pool_1(x)\n",
    "        \n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = self.pool_2(x)\n",
    "        \n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = self.pool_3(x)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.hidden_1(x.view(-1,1344))))\n",
    "        x = self.dropout(F.relu(self.hidden_2(x)))\n",
    "        x = self.output_layer(x)\n",
    "        x = self.classification_fn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Load SpinNet model (which has already been trained on our dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is selecting the custom model\n",
    "model = SpinNET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training model if required\n",
    "state_dict = torch.load('spinnet_trained_2.7.pth',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Real-time webcam demo (does not work on Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(0,cv2.CAP_DSHOW) # change to zero usually (I have 2 webcams)\n",
    "vc.set(cv2.CAP_PROP_FRAME_WIDTH, 1280.0)\n",
    "vc.set(cv2.CAP_PROP_FRAME_HEIGHT, 720.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,15*9/16))\n",
    "\n",
    "for i in range(100):\n",
    "    # get the frame\n",
    "    if vc.isOpened():\n",
    "        is_capturing, frame = vc.read()\n",
    "            \n",
    "    # resize the input image and convert to pytorch tensor\n",
    "    frame_small = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), dsize=(227, 128))\n",
    "    frame_tensor = torch.from_numpy(frame_small.astype(float).transpose(2,0,1)/256).view(1,3,128,227).float()\n",
    "    \n",
    "    # compute CNN output\n",
    "    if torch.cuda.is_available():\n",
    "        output = model(frame_tensor.cuda())\n",
    "    else:\n",
    "        output = model(frame_tensor)\n",
    "        \n",
    "    ps = torch.exp(output)\n",
    "    \n",
    "    # get index of maximum probaability - corresponds to the class\n",
    "    max_val,max_idx = ps[0].max(0)\n",
    "    \n",
    "    # update display\n",
    "    plt.clf()\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # show the original image (not downscaled version fed to CNN)\n",
    "    plt.axis(\"off\")\n",
    "    if(int(max_idx) == 0):\n",
    "        with plt.rc_context({'axes.titlecolor':'green'}):\n",
    "            plt.title(class_labels[int(max_idx)],fontsize=32)\n",
    "    else:\n",
    "        with plt.rc_context({'axes.titlecolor':'red'}):\n",
    "            plt.title(class_labels[int(max_idx)],fontsize=32)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    # fps\n",
    "    time.sleep(1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.release() # switch off the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
